<head>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css" integrity="sha384-t5CR+zwDAROtph0PXGte6ia8heboACF9R5l/DiY+WZ3P2lxNgvJkQk5n7GPvLMYw" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js" integrity="sha384-FaFLTlohFghEIZkw6VGwmf9ISTubWAVYW8tG8+w2LAIftJEULZABrF9PPFv+tVkH" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js" integrity="sha384-bHBqxz8fokvgoJ/sc17HODNxa42TlaEhB+w8ZJXTc2nZf1VgEaFZeZvT4Mznfz0v" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
</head>
# Evergreen Performance Bulletin 2021-03-08

As always, please let me know if you have any suggestions whatsoever.

Link to the [last](https://hhoke.github.io/evergreen_task_analysis/2021-03-08.html) and [next](https://hhoke.github.io/evergreen_task_analysis/2021-04-05.html) bulletins.

## Updates

### New Epic: Structured, Concern-aware Alerting

This will address many of the alerting difficulties outlined in last sprint's newsletter. [In Team Review](https://docs.google.com/document/d/1RRWS0auwTZ6PyeC43p-8QIvdE2ilJHLI5Jrqvta4TIc/edit)

### Replacement for Makespan Metric is Fixed

This is currently in the main Evergreen Dashboard, under the title "number of time chunks of length MaxDurationThreshold needed to clear queue with current hosts", because it's not really clear what "host queue ratio" means. The Y axis is logarithmic in order to allow visualization of the detail of day-to-day operations, which should top out at 1 if sufficient hosts have been provisioned, simultaneously with the moonshots that occur when `max_total_dynamic_hosts` has been reached.

"host queue ratio" is currently very useful. However the default MaxDurationThreshold, which is equivalent to the target time for the host allocator, is 30 minutes. Our long-term goal for task wait SLAs is something more like 5 minutes. If we use a lower MaxDurationThreshold to enable this, "host queue ratio" will become less informative, as it does not take into account long tasks. This presents a long-term threat to the paradigm, but only under certain conditions which it will most likely be possible to avoid.

## Future Directions

### Understanding Idle Time Tradeoffs

This is the most important new area of inquiry, IMO. That is to say, it has the greatest expected value for return on information.

There are three main reasons we need to better understand the tradeoffs associated with host idleness:

1. Savings: We spend hundreds of thousands of dollars on idle hosts each year. However, we also spend hundreds of thousands of dollars on hosts that are spinning up and are not yet ready to run tasks. We could potentially save hundreds of thousands of dollars a year by understanding how to minimize the total time host spend idle or spinning up. It may also be the case that there are better or worse configurations for performance that cost similarly.
2. Windows Performance: We currently regulate windows host costs by setting low distro-level max hosts limits. This results in very bad performance. It might be possible to get equivalent cost savings without as heavy as a toll on performance. 
3. Making sure performance increases aren't too costly: In general, I think it is a good idea to have some kind of feedback rule that increases host allocation as a response to poor performance (e.g. time since queue was last cleared, number of long-wait tasks). However, this will likely result in greater idle time. Before we take any action that significantly increases the host idle time, we should understand the tradeoffs.

I've begun to look into this. Some important facts and preliminary work:

#### startup considerations for dynamic distros

Brian informed me that typical dynamic host time-to-start is on the order of 2 minutes or so. 
As such, we might be able to get significant idle-time savings simply by cutting the idle time threshold from 4 minutes to 2.
However, this depends on the performance of `FindNextTask(`.
We can describe the wasted-time tradeoffs as such:

<img src="https://render.githubusercontent.com/render/math?math=\mathbf{E}(\text{unused%20host%20time})=\mathbf{E}(\text{idle%20time})%20+%20\mathbf{E}(\text{startup%20time})">

That is, given that a task may need to be picked up by a host at some unknown time, there is some chance we will have costs associated with waiting for a task, and if we terminate the host but need it later, we will have to waste startup time, as no tasks can run then either.
As, e.g., __E__(idle time|idle termination) = `idle_threshold_time`, we can complicate this in a revealing way:

$$
\mathbf{E}(\text{unused host time})=\mathbf{E}(\text{idle time}) + \mathbf{E}(\text{startup time})
$$

 __E__(unused host time) = __P__(idle termination)[__E__(idle time|idle termination) +  __E__(startup time|idle termination)]  __P__(need startup|)\__`mean_startup_time`  

 __E__(unused host time) = __E__(idle time|no idle termination) + __P__(need startup|)\__`mean_startup_time`

### Task Packing to decrease idle host time for Windows

I've been looking at windows-64-vs2017-large more closely, on account of its' poor performance.
There are idle hosts up to 2 hours after the queue is exhausted.
Currently, hosts request tasks as soon as they are free, which guarantees that the task at the head of the queue is taken off the queue in the fastest time possible.
However, in the case of windows distros, the performance is degraded to the point of multiple-hour waits, due to the distro max hosts limit.
We should modify our strategy, because it makes no sense to mind seconds and let hours go by.

We are currently able to predict when a queue is in terminal decline, using the new host queue ratio metric
One possibility would be to mark hosts nearing the end of their allotted hour as unable to accept new tasks, if the 
As such, if we were able to use some coordination step that added on the order of a minute to each task's wait, without worrying about modes, it would still be worth it if we were able to decrease idle time enough to justify the lifting of distro max host limits.


### Future Directions Not Considered

~~~

## Blotter

*(For one-off or temporary performance issues)*

#### 2021-02-24
set ubuntu1804-large back to fleet from on-demand

#### 2021-03-02

A putative issue with commit queue merge tasks was determined to be an illusion/misconception caused by the UI. A ticket has been created, and Maria has solved the UI issue conceptually, though it has not been implemented yet. [https://jira.mongodb.org/browse/EVG-14191](https://jira.mongodb.org/browse/EVG-14191)
