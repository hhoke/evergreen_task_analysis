<script type="text/javascript" charset="utf-8" 
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,
https://vincenttam.github.io/javascripts/MathJaxLocal.js"></script>

# Evergreen Performance Bulletin 2021-06-14

As always, please let me know if you have any suggestions whatsoever.

Link to the [last](https://hhoke.github.io/evergreen_task_analysis/2021-03-22.html) and [next](https://hhoke.github.io/evergreen_task_analysis/2021-06-14.html) bulletins.

## Updates

### New Epic: Structured, Granular Alerting with Prometheus Alert Manager

This will address many of the alerting difficulties outlined in prior newsletters. Scope is approved, and the epic is [second up to execute](https://docs.google.com/document/d/1RRWS0auwTZ6PyeC43p-8QIvdE2ilJHLI5Jrqvta4TIc/edit#heading=h.b1os3ai9s8t3).

#### fixing idle time metric

[Idle time metric is fixed.](https://jira.mongodb.org/browse/EVG-14363)

### Preliminary Results: Host Drawdown Job Reduces Idle Time ~5x.

In order to get a rough estimate of the effect of the termination jobs, I compared two queue-exhaustion events, one before I turned on the feature and one after.

Looking at the first event, we started at just under 1000 hosts. 
Five minutes after the queue zeroed out (roughly), we had 375 idle machines.

I then set the Host Overallocation Rule in the distro page to "terminate-hosts-when-overallocated".

For this second event, we started out at just over 1000 hosts, and pre-emptively killed about 400 hosts.
There were only 35 idle hosts 5 minutes after the event, for a roughly 10x reduction in idle hosts.

The average summed idle time, over the last four Fridays, was 60 thousand minutes.
UTC Friday 11th Jun has a summed idle time of 9,309 minutes, with an estimated 1552 extra startup minutes, for a roughly 5x reduction.

With an instance type of m4.xlarge, spot instances are currently $0.0663 per minute in NVA.
This new feature therefore provides, in the operation of rhel80-small, a savings of roughly 

$$(\frac{\$0.0663} {\text{Hour in N. Virginia}}) * (\frac{1 \text{ hr}} {60\text{ minutes}}) * (\frac{60000-9309\text{ minutes}}{\text{day}})  \approx \frac{\$56}{day} $$

more generally,

$$(\frac{\$\text{price}} {\text{Hour in N. Virginia}}) * (\frac{1 \text{ hr}} {60\text{ minutes}}) * (\frac{\text{task runtime minutes}}{\text{day}}) * \text{fraction of time saved} \approx \frac{\$56}{day} $$

This represents roughly $17k/yr savings for the operation of rhel80-small, based on an average idle time per day of 50784 over the last 30 days.

The current spot price of m4.2xlarge is $0.1924 per hour, which gives $49.5k/yr by the above equation.
As load is largely similar between the two distros, this should mean that we could save around $67k/yr using this feature just on these two distros, assuming we use spot and never on-demand.

#### What about Additional Costs?

2 additional costs come to mind:
1) additional spinup/provisioning time
2) QOS degradation

1: can we measure provisioning time?

yes, roughly 1552 minutes extra on friday.

#### experimentation standards

The current plan to evaluate the effect of idle host changes is to turn on new features on alternate Wednesdays.
In other words, I will be using a [within-subject design](https://web.archive.org/web/20210225195756/https://www.nngroup.com/articles/between-within-subjects/).
This will avoid distro matching problems that would be caused by a split treatment by distro (i.e, between-subject design).
First, I need to get an idea of what idle host time metric to use, and what its variability is [EVG-14410](https://jira.mongodb.org/browse/EVG-14410). 
This will allow me to conduct power analysis to make sure that we will be able to identify an effect if one exists.

## Future Directions

### Understanding Idle Time Tradeoffs

This is the most important new area of inquiry, IMO. That is to say, it has the greatest expected value for return on information.

There are three main reasons we need to better understand the tradeoffs associated with host idleness:

1. Savings: We could potentially save hundreds of thousands of dollars a year by understanding how to minimize the total time host spend idle or spinning up. It may also be the case that there are better or worse configurations for performance with similar costs.
2. Windows Performance: We currently regulate windows host costs by setting low distro-level max hosts limits. This results in very bad performance. It might be possible to get equivalent cost savings without as heavy as a toll on performance. 
3. Making sure performance increases aren't too costly: In general, I think it is a good idea to have some kind of feedback rule that increases host allocation as a response to poor performance (e.g. time since queue was last cleared, number of long-wait tasks). However, this will likely result in greater idle time. Before we take any action that significantly increases the host idle time, we should understand the tradeoffs.

I've begun to look into this. Some important facts and preliminary work:

## Follow Up On [EVG-14350](https://jira.mongodb.org/browse/EVG-14350).

Based on [previous work](https://hhoke.github.io/evergreen_task_analysis/2021-03-08.html), I decided a heuristic based on a low-enough value of host queue ratio would allow us to decrease idle time by a lot, while avoiding impacts on performance.
Pending a more rigorous analysis, this appears to be correct.

#### Task Packing to decrease idle host time for Windows

I've been looking at windows-64-vs2017-large more closely, on account of its poor performance.
There are idle hosts up to 2 hours after the queue is exhausted.
Currently, hosts request tasks as soon as they are free, which guarantees that the task at the head of the queue is taken off the queue in the fastest time possible.
However, in the case of windows distros, the performance is degraded to the point of multiple-hour waits, due to the distro max hosts limit.
We should modify our strategy, because it makes no sense to mind seconds and let hours go by.

We are currently able to predict when a queue is in terminal decline, using the new host queue ratio metric.
As such, if we were able to use some coordination step that added about a minute to each task's wait, without worrying about modes, it would still be worth it if we were able to decrease idle time enough to justify the lifting of distro max host limits.
However, this could involve significant reworking of the task scheduling framework.

Another possibility would be to mark hosts nearing the end of their allotted hour as unable to accept new tasks, if the host queue ratio is low enough.

A third possibility is to have hosts include the amount of time they have left in their current hour when requesting tasks, and only accept tasks that are less than that amount of time. 

This needs to be thought out more before it is implemented.

### Future Directions Not Considered

~~~

## Blotter

*(For one-off or temporary performance issues)*

